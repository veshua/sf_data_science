{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:53:47</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:31:16</td>\n",
       "      <td>City of Lost Children, The (Cité des enfants p...</td>\n",
       "      <td>Adventure|Drama|Fantasy|Mystery|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:33:39</td>\n",
       "      <td>Twelve Monkeys (a.k.a. 12 Monkeys) (1995)</td>\n",
       "      <td>Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:32:07</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2005-04-02 23:29:40</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating            timestamp  \\\n",
       "0       1        2     3.5  2005-04-02 23:53:47   \n",
       "1       1       29     3.5  2005-04-02 23:31:16   \n",
       "2       1       32     3.5  2005-04-02 23:33:39   \n",
       "3       1       47     3.5  2005-04-02 23:32:07   \n",
       "4       1       50     3.5  2005-04-02 23:29:40   \n",
       "\n",
       "                                               title  \\\n",
       "0                                     Jumanji (1995)   \n",
       "1  City of Lost Children, The (Cité des enfants p...   \n",
       "2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
       "3                        Seven (a.k.a. Se7en) (1995)   \n",
       "4                         Usual Suspects, The (1995)   \n",
       "\n",
       "                                   genres  \n",
       "0              Adventure|Children|Fantasy  \n",
       "1  Adventure|Drama|Fantasy|Mystery|Sci-Fi  \n",
       "2                 Mystery|Sci-Fi|Thriller  \n",
       "3                        Mystery|Thriller  \n",
       "4                  Crime|Mystery|Thriller  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv(\"data/movie.csv\")\n",
    "ratings = pd.read_csv(\"data/rating.csv\")\n",
    "df=pd.merge(ratings,movies, how='left',on='movieId')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pulp Fiction (1994)', 'Forrest Gump (1994)',\n",
      "       'Shawshank Redemption, The (1994)', 'Silence of the Lambs, The (1991)',\n",
      "       'Jurassic Park (1993)'],\n",
      "      dtype='object', name='title')\n"
     ]
    }
   ],
   "source": [
    "movie_popularity = df[\"title\"].value_counts()\n",
    "print(movie_popularity.head().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   rating\n",
      "title                                                    \n",
      "Yonkers Joe (2008)                                    5.0\n",
      "Year Zero: The Silent Death of Cambodia (1979)        5.0\n",
      "Who Killed Vincent Chin? (1987)                       5.0\n",
      "When I Walk (2013)                                    5.0\n",
      "Welcome to Australia (1999)                           5.0\n",
      "Victor and the Secret of Crocodile Mansion (2012)     5.0\n",
      "Turkish Dance, Ella Lola (1898)                       5.0\n",
      "This Thing With Sarah (2013)                          5.0\n",
      "The great match (2007)                                5.0\n",
      "The Wrecking Crew (2008)                              5.0\n"
     ]
    }
   ],
   "source": [
    "average_rating_df = df[[\"title\", \"rating\"]].groupby('title').mean()\n",
    "\n",
    "sorted_average_ratings = average_rating_df.sort_values(by=[\"rating\",'title'], ascending=False)\n",
    "\n",
    "print(sorted_average_ratings.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10472\n"
     ]
    }
   ],
   "source": [
    "movie_popularity = df[\"title\"].value_counts()\n",
    "popular_movies = movie_popularity[movie_popularity > 50].index\n",
    "\n",
    "print(popular_movies.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 rating\n",
      "title                                                  \n",
      "Shawshank Redemption, The (1994)               4.446990\n",
      "Godfather, The (1972)                          4.364732\n",
      "Usual Suspects, The (1995)                     4.334372\n",
      "Schindler's List (1993)                        4.310175\n",
      "Godfather: Part II, The (1974)                 4.275641\n",
      "Seven Samurai (Shichinin no samurai) (1954)    4.274180\n",
      "Rear Window (1954)                             4.271334\n",
      "Band of Brothers (2001)                        4.263182\n",
      "Casablanca (1942)                              4.258327\n",
      "Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)  4.256935\n"
     ]
    }
   ],
   "source": [
    "movie_popularity = df[\"title\"].value_counts()\n",
    "popular_movies = movie_popularity[movie_popularity > 50].index\n",
    "df2 = df[df.title.isin(popular_movies)]\n",
    "average_rating_df2 = df2[[\"title\", \"rating\"]].groupby('title').mean()\n",
    "\n",
    "sorted_average_ratings = average_rating_df2.sort_values(by=[\"rating\",'title'], ascending=False)\n",
    "\n",
    "print(sorted_average_ratings.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала загрузим датасет \"Articles sharing and reading from CI&T DeskDrop\", включающий в себя собранные за один год логи DeskDrop — платформы для внутренних коммуникаций, разработанной CI&T и ориентированной на компании, использующие Google Workspace (Google G Suite). Среди прочего, эта платформа позволяет сотрудникам компаний делиться актуальными статьями со своими коллегами.\n",
    "\n",
    "В датасете содержится около 73 тысяч записей о взаимодействии пользователей с более чем тремя тысячами публичных статей, размещённых на платформе.\n",
    "\n",
    "Информация в наборе данных:\n",
    "Данные включают в себя два файла:\n",
    "\n",
    "shared_articles.csv;\n",
    "users_interactions.csv.\n",
    "Начнём работать с файлом shared_articles.csv. Он содержит информацию о статьях, опубликованных на платформе DeskDrop.\n",
    "\n",
    "Для каждой статьи есть:\n",
    "Для временной метки существует два возможных типа событий:\n",
    "\n",
    "CONTENT SHARED — статья была опубликована на платформе и доступна для пользователей;\n",
    "CONTENT REMOVED — статья была удалена с платформы и недоступна для дальнейших рекомендаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv(\"data/shared_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Отфильтруйте данные так, чтобы остались только объекты с типом события CONTENT SHARED. Сколько таких объектов в получившейся таблице?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3047"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df[articles_df['eventType']=='CONTENT SHARED']['contentId'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь откроем второй файл — users_interactions.csv.\n",
    "\n",
    "Давайте предварительно преобразуем столбцы personId, contentId в таблицах к строкам. Это преобразование пригодится нам в дальнейшем:\n",
    "\n",
    "- interactions_df.personId = interactions_df.personId.astype(str)\n",
    "- interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "- articles_df.contentId = articles_df.contentId.astype(str)\n",
    "\n",
    "В колонке eventType описаны действия, которые могли совершать пользователи при взаимодействии со статьёй:\n",
    "\n",
    "- VIEW — просмотр,\n",
    "- LIKE — лайк,\n",
    "- COMMENT CREATED — комментарий,\n",
    "- FOLLOW — подписка,\n",
    "- BOOKMARK — добавление в закладки.\n",
    "\n",
    "В первую очередь нам необходимо понять, как определить, что какая-то статья популярнее других. Если бы из возможных реакций у нас были только лайки или только просмотры, то статьи было бы легко ранжировать в соответствии с этими значениями. Однако у нас есть информация о различных действиях пользователя, и на её основе мы должны создать некий универсальный индекс популярности. Составим его из реакций пользователей, придав им разные веса:\n",
    "\n",
    "event_type = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  }\n",
    "   \n",
    "Веса здесь подобраны исходя из важности каждого действия: оставить комментарий — значит, показать наибольшую вовлечённость, а обычный просмотр, напротив, демонстрирует наименьшую вовлечённость.\n",
    "\n",
    "Создайте признак, который будет отражать числовой вес для взаимодействия со статьёй (в соответствии с приведёнными выше весами). Вычислите среднее значение для полученного признака. Округлите его до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2362885828078327"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df = pd.read_csv('data/users_interactions.csv')\n",
    "interactions_df.personId = interactions_df.personId.astype(str)\n",
    "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "articles_df.contentId = articles_df.contentId.astype(str)\n",
    "event_type_strength = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}\n",
    "interactions_df['eventStrength'] = interactions_df.eventType.apply(lambda x: event_type_strength[x])\n",
    "interactions_df['eventStrength'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы говорили, что рекомендательные системы подвержены проблеме холодного старта — в таких случаях создавать рекомендации намного сложнее.\n",
    "\n",
    "Чтобы получить хоть какую-то информацию, на которую можно будет опираться, оставьте только тех пользователей, которые взаимодействовали хотя бы с пятью статьями. Сколько всего таких пользователей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = (\n",
    "    interactions_df\n",
    "    .groupby(['personId', 'contentId'])\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby('personId').size())\n",
    "\n",
    "users_with_enough_interactions_df = \\\n",
    "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "\n",
    "print(len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь оставим только те взаимодействия, которые касаются только отфильтрованных пользователей (то есть тех, которые взаимодействовали как минимум с пятью статьями). Сколько всего таких взаимодействий?\n",
    "\n",
    "В этом задании необходимо работать с данными, полученными в предыдущем задании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69868, 9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "interactions_from_selected_users_df = interactions_df.loc[np.in1d(interactions_df.personId,\n",
    "            users_with_enough_interactions_df)]\n",
    "print(interactions_from_selected_users_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас каждое отдельное взаимодействие пользователя со статьёй выделено в отдельную запись, то есть пользователь мог просмотреть статью, лайкнуть и прокомментировать её, и всё это отразилось в трёх действиях. Давайте для удобства соединим все эти действия в некоторый коэффициент, который будет отражать интерес пользователя к статье. Так как каждому возможному действию мы ранее уже присвоили вес, то, по сути, нам нужно просто сложить все действия. Однако полученное число будет увеличиваться с количеством действий, и будет очень большой разброс возможных значений. В таких случаях обычно логарифмируют полученный результат с помощью следующей функции:\n",
    "\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "\n",
    "Примените упомянутое выше преобразование для логарифмирования к сумме весов для взаимодействия пользователя с каждой конкретной статьёй. Также сохраните для каждой пары «пользователь — статья» значение времени последнего взаимодействия.\n",
    "\n",
    "Найдите среднее по признаку с получившимися временными отсечками. Округлите результат до двух знаков после точки-разделителя.\n",
    "\n",
    "Так как наши данные отсортированы по дате, то для того, чтобы выбрать последнее взаимодействие, необходимо использовать метод max()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470605340.0403006"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId']).eventStrength.sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index().set_index(['personId', 'contentId'])\n",
    ")\n",
    "interactions_full_df['last_timestamp'] = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId'])['timestamp'].max()\n",
    ")\n",
    "        \n",
    "interactions_full_df = interactions_full_df.reset_index()\n",
    "interactions_full_df['last_timestamp'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разумеется, для того чтобы впоследствии оценить качество построенной рекомендательной системы, нам нужно разделить выборку на обучающую и тестовую. Так как в реальности рекомендации строятся на основе исторических данных о пользователе и контенте, сделаем в нашей задаче разбиение на обучающую и тестовую выборки по временной отсечке.\n",
    "\n",
    "Разделите данные на обучающую и тестовую выборки, выбрав в качестве временной отсечки значение 1475519545. Сколько объектов попало в обучающую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29325\n"
     ]
    }
   ],
   "source": [
    "split_ts = 1475519545\n",
    "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
    "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n",
    "\n",
    "print(len(interactions_train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства дальнейшего измерения качества рекомендаций преобразуйте данные так, чтобы получить таблицу в формате, где строка соответствует пользователю, а столбцы будут истинными предпочтениями и рекомендациями в формате списков. На место пустых ячеек поместите пустые списки.\n",
    "\n",
    "Осталось совсем немного — скоро вы получите свою первую систему рекомендаций! Мы будем строить popular-based-модель, а значит, нам необходимо найти самые популярные статьи.\n",
    "\n",
    "Посчитайте популярность каждой статьи как сумму всех логарифмических «оценок» взаимодействий с ней (используя только обучающую выборку). Выберите ID самой популярной статьи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-6783772548752091658'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular = (\n",
    "    interactions_train_df\n",
    "    .groupby('contentId')\n",
    "    .eventStrength.sum().reset_index()\n",
    "    .sort_values('eventStrength', ascending=False)\n",
    "    .contentId.values\n",
    ")\n",
    "popular[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо сформировать рекомендации для каждого пользователя. Будем рекомендовать десять самых популярных статей. Также необходимо помнить, что следует предлагать пользователю только то, что он ещё не читал.\n",
    "\n",
    "Постройте систему рекомендаций. Оцените качество с помощью precision@10 для каждого пользователя (доля угаданных рекомендаций). После этого усредните результат по всем пользователям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'true_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_18346/4013237115.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'true_train'"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "final_df['popular'] = (\n",
    "    final_df.true_train\n",
    "    .apply(\n",
    "        lambda x:\n",
    "        popular[~np.in1d(popular, x)][:top_k]\n",
    "    )\n",
    ")\n",
    "def calc_precision(column):\n",
    "    return (\n",
    "        final_df\n",
    "        .apply(\n",
    "            lambda row:\n",
    "            len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) /\n",
    "            min(len(row['true_test']) + 0.001, 10.0),\n",
    "            axis=1)).mean()\n",
    "    \n",
    "calc_precision('popular')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
