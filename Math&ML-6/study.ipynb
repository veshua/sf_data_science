{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте потренируемся применять стохастический градиентный спуск для решения задачи линейной регрессии. Мы уже рассмотрели его реализацию «с нуля», однако для решения практических задач можно использовать готовые библиотеки.\n",
    "\n",
    "Загрузите стандартный датасет об алмазах из библиотеки Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import ssl\n",
    "ssl._create_default_https_context=ssl._create_unverified_context\n",
    "df = sns.load_dataset('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалите часть признаков:\n",
    "\n",
    "df.drop(['depth', 'table', 'x', 'y', 'z'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Закодируйте категориальные признаки:\n",
    "import pandas as pd\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Логарифмируйте признаки:\n",
    "import numpy as np\n",
    "df['carat'] = np.log(1+df['carat'])\n",
    "df['price'] = np.log(1+df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определите целевую переменную и предикторы:\n",
    "\n",
    "X = df.drop(columns=\"price\")\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите выборку на обучающую и тестовую (объём тестовой возьмите равным 0.33), значение random_state должно быть равно 42.\n",
    "\n",
    "Теперь реализуйте алгоритм линейной регрессии со стохастическим градиентным спуском (класс SGDRegressor). Отберите с помощью GridSearchCV оптимальные параметры по следующей сетке:\n",
    "\n",
    "\"loss\": [\"squared_error\", \"epsilon_insensitive\"],\\\n",
    "\"penalty\": [\"elasticnet\"],\\\n",
    "\"alpha\": np.logspace(-3, 3, 10),\\\n",
    "\"l1_ratio\": np.linspace(0, 1, 10),\\\n",
    "\"learning_rate\": [\"constant\"],\\\n",
    "\"eta0\": np.logspace(-4, -1, 4)\n",
    "\n",
    "Обучите регрессию с оптимальными параметрами. В качестве ответа введите получившееся значение MSE, предварительно округлив его до третьего знака после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'eta0': 0.001, 'l1_ratio': 0.0, 'learning_rate': 'constant', 'loss': 'epsilon_insensitive', 'penalty': 'elasticnet'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.044"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "parameters = {\n",
    "    \"loss\": [\"squared_error\", \"epsilon_insensitive\"],\n",
    "    \"penalty\": [\"elasticnet\"],\n",
    "    \"alpha\": np.logspace(-3, 3, 10),\n",
    "    \"l1_ratio\": np.linspace(0, 1, 10),\n",
    "    \"learning_rate\": [\"constant\"],\n",
    "    \"eta0\": np.logspace(-4, -1, 4)\n",
    "}\n",
    "\n",
    "sgd = SGDRegressor(random_state=42)\n",
    "sgd_cv = GridSearchCV(estimator=sgd, param_grid=parameters, n_jobs=-1)\n",
    "sgd_cv.fit(X_train, y_train)\n",
    "\n",
    "print(sgd_cv.best_params_)\n",
    "\n",
    "sgd = SGDRegressor(**sgd_cv.best_params_, random_state = 42)\n",
    "\n",
    "sgd.fit(X_train, y_train)\n",
    "sgd.score(X_train, y_train) # r2\n",
    "ls = sgd.predict(X_test)\n",
    "\n",
    "round(mean_squared_error(y_test, ls), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296335078534031\n",
      "0.6286680781673306\n",
      "0.6286669787778999\n",
      "0.6286669787764609\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 6*x**5-5*x**4-4*x**3+3*x**2\n",
    " \n",
    "def func2(x):\n",
    "    return 30*x**4-20*x**3-12*x**2+6*x\n",
    "\n",
    "init_value = 0.7\n",
    "iter_count = 0\n",
    "x_curr = init_value\n",
    "epsilon = 0.000001\n",
    "f = func1(x_curr)\n",
    " \n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)\n",
    "    \n",
    "print(iter_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.695121951219512\n",
      "11.734125501243229\n",
      "7.1123493600499685\n",
      "5.365000391507974\n",
      "5.015260627016227\n",
      "5.000029000201801\n",
      "5.000000000105126\n",
      "5.000000000000001\n"
     ]
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 3*x**2 - 6*x -45\n",
    "def func2(x):\n",
    "    return 6*x - 6\n",
    "initial_value = 42\n",
    "iter_count = 0\n",
    "x_curr = initial_value\n",
    "epsilon = 0.0001\n",
    "f = func1(x_curr)\n",
    "\n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Можно объединить всё в одну функцию:\n",
    "    \n",
    "def newtons_method(f, fprime, x0, tol=0.0001):\n",
    "    iter_count = 0\n",
    "    x_curr = x0\n",
    "    f_val = f(x_curr)\n",
    "    while (abs(f_val) > tol):\n",
    "        f_val = f(x_curr)\n",
    "        f_prime_val = fprime(x_curr)\n",
    "        x_curr = x_curr - (f_val)/(f_prime_val)\n",
    "        iter_count += 1\n",
    "    return x_curr\n",
    "\n",
    "newtons_method(f=func1, fprime=func2, x0=50, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# А можно воспользоваться реализацией из библиотеки scipy:\n",
    "\n",
    "from scipy.optimize import newton\n",
    "newton(func=func1, fprime=func2, x0=50, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1666666807529666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 24*x**2 - 4*x\n",
    "def func2(x):\n",
    "    return 48*x - 4\n",
    "newton(func=func1, fprime=func2, x0=42, tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Определим функцию, которую будем оптимизировать. Вместо отдельных x и y можно взять координаты единого вектора:\n",
    "\n",
    "def func(x):\n",
    "    return x[0]**2.0 + x[1]**2.0\n",
    "\n",
    "# Теперь определим градиент для функции:\n",
    "\n",
    "def grad_func(x):\n",
    "    return np.array([x[0] * 2, x[1] * 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации Optimization terminated successfully.\n",
      "Количество оценок: 3\n",
      "Решение: f([0. 0.]) = 0.00000\n"
     ]
    }
   ],
   "source": [
    "# Зададим начальную точку:\n",
    "x_0 = [1.0, 1.0]\n",
    "\n",
    "# Определим алгоритм:\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "\n",
    "# Выведем результаты:\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили, что минимум функции достигается в точке (0, 0). Значение функции в этой точке также равно нулю. \n",
    "\n",
    "Можно повторить то же самое с вариацией  L-BFGS-B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Количество оценок: 3\n",
      "Решение: f([0. 0.]) = 0.00000\n"
     ]
    }
   ],
   "source": [
    "# определяем нашу функцию\n",
    "def func(x):\n",
    "    return x[0]**2.0 + x[1]**2.0\n",
    " \n",
    "#  определяем градиент функции\n",
    "def grad_func(x):\n",
    "    return np.array([x[0] * 2, x[1] * 2])\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = [1, 1]\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат будет тем же самым.\n",
    "\n",
    "→ Иногда количество итераций у двух модификаций различается, но ответ совпадает. Бывает также, что одна из вариаций может не сойтись, а другая — достичь экстремума, поэтому советуем не воспринимать их как взаимозаменяемые алгоритмы. На практике лучше пробовать разные варианты: если у вас не сошёлся алгоритм BFGS, можно попробовать L-BFGS-B, и наоборот. Также можно экспериментировать одновременно с обоими алгоритмами, чтобы выбрать тот, который будет сходиться для функции за меньшее число итераций и тем самым экономить время.\n",
    "\n",
    "→ Важно понимать, что для некоторых функций не из всех стартовых точек получается достичь сходимости метода. Тогда их можно перебирать, к примеру, с помощью цикла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Количество оценок: 9\n",
      "Решение: f([-3.99999972  1.00000028]) = -1.00000\n"
     ]
    }
   ],
   "source": [
    "# определяем нашу функцию\n",
    "def func(x):\n",
    "    return x[0]**2.0 - x[0]*x[1] + x[1]**2 + 9*x[0] - 6*x[1] + 20\n",
    " \n",
    "#  определяем градиент функции\n",
    "def grad_func(x):\n",
    "    return np.array([2*x[0] - x[1] + 9, -x[0] + 2*x[1] - 6])\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = [-400, -400]\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='L-BFGS-B', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статус оптимизации Optimization terminated successfully.\n",
      "Количество оценок: 37\n",
      "Решение: f([1.31617159e-02 6.65344582e-14]) = 10.00000\n"
     ]
    }
   ],
   "source": [
    "# определяем нашу функцию\n",
    "def func(x):\n",
    "    return x[0]**4 + 6*x[1]**2 + 10\n",
    " \n",
    "#  определяем градиент функции\n",
    "def grad_func(x):\n",
    "    return np.array([4*x[0]**3, 12*x[1]])\n",
    " \n",
    "# определяем начальную точку\n",
    "x_0 = [100, 100]\n",
    "# реализуем алгоритм L-BFGS-B\n",
    "result = minimize(func, x_0, method='BFGS', jac=grad_func)\n",
    "# получаем результат\n",
    "print('Статус оптимизации %s' % result['message'])\n",
    "print('Количество оценок: %d' % result['nfev'])\n",
    "solution = result['x']\n",
    "evaluation = func(solution)\n",
    "print('Решение: f(%s) = %.5f' % (solution, evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример № 1. SciPy (scipy.optimize.linprog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "values = [4, 2, 1, 7, 3, 6] #стоимости товаров\n",
    "weights = [5, 9, 8, 2, 6, 5] #вес товаров\n",
    "C = 15 #вместимость сумки\n",
    "n = 6 #количество товаров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь нам необходимо вспомнить линейную алгебру, так как очень важно, чтобы векторы были в нужных нам размерностях, иначе мы не сможем использовать матричное умножение. Вектор A размера 6 мы превращаем в матрицу размера (1, 6) с помощью функции expand_dims(). Создаём все необходимые переменные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = - np.array(values) #изменяем знак, чтобы перейти от задачи максимизации к задаче минимизации\n",
    "A = np.array(weights)  #конвертируем список с весами в массив\n",
    "A = np.expand_dims(A, 0) #преобразуем размерность массива\n",
    "b = np.array([C]) #конвертируем вместимость в массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        message: Optimization terminated successfully. (HiGHS Status 7: Optimal)\n",
       "        success: True\n",
       "         status: 0\n",
       "            fun: -52.5\n",
       "              x: [ 0.000e+00  0.000e+00  0.000e+00  7.500e+00  0.000e+00\n",
       "                   0.000e+00]\n",
       "            nit: 0\n",
       "          lower:  residual: [ 0.000e+00  0.000e+00  0.000e+00  7.500e+00\n",
       "                              0.000e+00  0.000e+00]\n",
       "                 marginals: [ 1.350e+01  2.950e+01  2.700e+01  0.000e+00\n",
       "                              1.800e+01  1.150e+01]\n",
       "          upper:  residual: [       inf        inf        inf        inf\n",
       "                                    inf        inf]\n",
       "                 marginals: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
       "                              0.000e+00  0.000e+00]\n",
       "          eqlin:  residual: []\n",
       "                 marginals: []\n",
       "        ineqlin:  residual: [ 0.000e+00]\n",
       "                 marginals: [-3.500e+00]\n",
       " mip_node_count: 0\n",
       " mip_dual_bound: 0.0\n",
       "        mip_gap: 0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Передаём подготовленные переменные в оптимизатор SciPy:\n",
    "\n",
    "from scipy.optimize import linprog\n",
    "linprog(c=c, A_ub=A, b_ub=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример № 2. CVXPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова решим задачу из примера № 1, но уже предположим, что товары нельзя дробить, и будем решать задачу целочисленного линейного программирования.\n",
    "\n",
    "SciPy не умеет решать такие задачи, поэтому будем использовать новую библиотеку CVXPY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cvxpy.Variable(shape=n, integer=True)\n",
    "constraint = cvxpy.sum(cvxpy.multiply(A, x)) <= C\n",
    "x_positive = x >= 0\n",
    "total_value = cvxpy.sum(cvxpy.multiply(x, c))\n",
    "\n",
    "problem = cvxpy.Problem(\n",
    "    cvxpy.Minimize(total_value), constraints=[constraint, x_positive]\n",
    ")\n",
    "\n",
    "problem.solve()\n",
    "x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cvxpy.Variable(shape=n, boolean=True)\n",
    "constraint = cvxpy.sum(cvxpy.multiply(A, x)) <= C\n",
    "x_positive = x >= 0\n",
    "total_value = cvxpy.sum(cvxpy.multiply(x, c))\n",
    "\n",
    "problem = cvxpy.Problem(\n",
    "    cvxpy.Minimize(total_value), constraints=[constraint, x_positive]\n",
    ")\n",
    "\n",
    "problem.solve()\n",
    "x.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример № 3. PuLP\n",
    "\n",
    "В нашей каршеринговой компании две модели автомобилей: модель A и модель B. Автомобиль A даёт прибыль в размере 20 тысяч в месяц, а автомобиль B — 45 тысяч в месяц. Мы хотим заказать на заводе новые автомобили и максимизировать прибыль. Однако на производство и ввод в эксплуатацию автомобилей понадобится время:\n",
    "\n",
    "Проектировщику требуется 4 дня, чтобы подготовить документы для производства каждого автомобиля типа A, и 5 дней — для каждого автомобиля типа B.\n",
    "Заводу требуется 3 дня, чтобы изготовить модель A, и 6 дней, чтобы изготовить модель B.\n",
    "Менеджеру требуется 2 дня, чтобы ввести в эксплуатацию в компании автомобиль A, и 7 дней —  автомобиль B.\n",
    "Каждый специалист может работать суммарно 30 дней.\n",
    "\n",
    "Целевая функция будет выглядеть следующим образом: 20000*A + 45000*B\n",
    "\n",
    "Также запишем ограничения:\n",
    "- A, B >= 0\n",
    "- 4A + 5B <= 30\n",
    "- 3A + 6B <= 30\n",
    "- 2A + 7B <= 30\n",
    "\n",
    "Заметьте, что здесь мы снова пишем обычные неравенства, а не условия в матричном виде. Дело в том, что для данной библиотеки так «удобнее», так как она принимает все условия в «первичном» виде.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pulp/pulp.py:1298: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pulp/solverdir/cbc/osx/64/cbc /var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/1ae026a56de24f48989ec8bbe93a23b8-pulp.mps -max -timeMode elapsed -branch -printingOptions all -solution /var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/1ae026a56de24f48989ec8bbe93a23b8-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 8 COLUMNS\n",
      "At line 21 RHS\n",
      "At line 25 BOUNDS\n",
      "At line 28 ENDATA\n",
      "Problem MODEL has 3 rows, 2 columns and 6 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 216667 - 0.00 seconds\n",
      "Cgl0004I processed model has 3 rows, 2 columns (2 integer (0 of which binary)) and 6 elements\n",
      "Cutoff increment increased from 1e-05 to 5000\n",
      "Cbc0012I Integer solution of -195000 found by DiveCoefficient after 0 iterations and 0 nodes (0.00 seconds)\n",
      "Cbc0012I Integer solution of -200000 found by DiveCoefficient after 1 iterations and 0 nodes (0.00 seconds)\n",
      "Cbc0013I At root node, 0 cuts changed objective from -216666.67 to -200000 in 2 passes\n",
      "Cbc0014I Cut generator 0 (Probing) - 0 row cuts average 0.0 elements, 2 column cuts (2 active)  in 0.000 seconds - new frequency is 1\n",
      "Cbc0014I Cut generator 1 (Gomory) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 2 (Knapsack) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 3 (Clique) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 4 (MixedIntegerRounding2) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0014I Cut generator 5 (FlowCover) - 0 row cuts average 0.0 elements, 0 column cuts (0 active)  in 0.000 seconds - new frequency is -100\n",
      "Cbc0001I Search completed - best objective -200000, took 1 iterations and 0 nodes (0.00 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from -216667 to -200000\n",
      "Probing was tried 2 times and created 2 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 2 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 2 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 2 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 2 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 2 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 1 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                200000.00000000\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               1\n",
      "Time (CPU seconds):             0.00\n",
      "Time (Wallclock seconds):       0.00\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.01\n",
      "\n",
      "Количество автомобилей модели А:  1.0\n",
      "Количество автомобилей модели В:  4.0\n",
      "Суммарный доход:  200000.0\n"
     ]
    }
   ],
   "source": [
    "from pulp import *\n",
    "problem = LpProblem('Производство машин', LpMaximize)\n",
    "A = LpVariable('Автомобиль A', lowBound=0 , cat=LpInteger)\n",
    "B = LpVariable('Автомобиль B', lowBound=0 , cat=LpInteger)\n",
    "#Целевая функция\n",
    "problem += 20000*A + 45000*B \n",
    "#Ограничения\n",
    "problem += 4*A + 5*B <= 30 \n",
    "problem += 3*A + 6*B <=30\n",
    "problem += 2*A + 7*B <=30\n",
    "problem.solve()\n",
    "print(\"Количество автомобилей модели А: \", A.varValue)\n",
    "print(\"Количество автомобилей модели В: \", B.varValue)\n",
    "print(\"Суммарный доход: \", value(problem.objective))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
