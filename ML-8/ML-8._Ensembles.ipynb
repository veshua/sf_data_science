{"cells":[{"cell_type":"markdown","metadata":{"id":"2jedSZuufD16"},"source":["# ML-8. Ансамблирование. Бэггинг, стекинг, бустинг"]},{"cell_type":"markdown","metadata":{},"source":["Для этого возьмём датасет по решению задачи на прогрессирование диабета. Мы будем предсказывать уровень прогрессирования болезни относительно базового уровня (некоторая численная мера, насколько «сильно» болен пациент диабетом). Минимальное значение составляет 25, максимальное — 346. Далее посмотрим на распределение, чтобы убедиться, что это не многоклассовая классификация, данные нормированы и закодированы категориальным кодировщиком. \n","\n","Качество будем измерять по среднему квадрату ошибки (MSE) на кросс-валидации с точностью до второго знака после запятой. \n","\n","Для чистоты эксперимента возьмём решающее дерево с глубиной 10 (DecisionTreeRegressor) и случайный лес из 10 деревьев (параметр n_estimators) с глубиной 10 (RandomForestRegression). Предлагается исполнить код:"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1651231710084,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"vw5ijEbll0PC"},"outputs":[],"source":["# Импортируем библиотеки\n","from sklearn.datasets import load_diabetes\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"g_OshGB6zOla"},"source":["**Загрузка данных**"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1651231710482,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"2WP5RDq1mSgK"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>bmi</th>\n","      <th>bp</th>\n","      <th>s1</th>\n","      <th>s2</th>\n","      <th>s3</th>\n","      <th>s4</th>\n","      <th>s5</th>\n","      <th>s6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.038076</td>\n","      <td>0.050680</td>\n","      <td>0.061696</td>\n","      <td>0.021872</td>\n","      <td>-0.044223</td>\n","      <td>-0.034821</td>\n","      <td>-0.043401</td>\n","      <td>-0.002592</td>\n","      <td>0.019907</td>\n","      <td>-0.017646</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.001882</td>\n","      <td>-0.044642</td>\n","      <td>-0.051474</td>\n","      <td>-0.026328</td>\n","      <td>-0.008449</td>\n","      <td>-0.019163</td>\n","      <td>0.074412</td>\n","      <td>-0.039493</td>\n","      <td>-0.068332</td>\n","      <td>-0.092204</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.085299</td>\n","      <td>0.050680</td>\n","      <td>0.044451</td>\n","      <td>-0.005670</td>\n","      <td>-0.045599</td>\n","      <td>-0.034194</td>\n","      <td>-0.032356</td>\n","      <td>-0.002592</td>\n","      <td>0.002861</td>\n","      <td>-0.025930</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.089063</td>\n","      <td>-0.044642</td>\n","      <td>-0.011595</td>\n","      <td>-0.036656</td>\n","      <td>0.012191</td>\n","      <td>0.024991</td>\n","      <td>-0.036038</td>\n","      <td>0.034309</td>\n","      <td>0.022688</td>\n","      <td>-0.009362</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.005383</td>\n","      <td>-0.044642</td>\n","      <td>-0.036385</td>\n","      <td>0.021872</td>\n","      <td>0.003935</td>\n","      <td>0.015596</td>\n","      <td>0.008142</td>\n","      <td>-0.002592</td>\n","      <td>-0.031988</td>\n","      <td>-0.046641</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        age       sex       bmi        bp        s1        s2        s3  \\\n","0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n","1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n","2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n","3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n","4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n","\n","         s4        s5        s6  \n","0 -0.002592  0.019907 -0.017646  \n","1 -0.039493 -0.068332 -0.092204  \n","2 -0.002592  0.002861 -0.025930  \n","3  0.034309  0.022688 -0.009362  \n","4 -0.002592 -0.031988 -0.046641  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Загрузим датасет из библиотеки\n","data = load_diabetes(as_frame=True)\n","# Создаем матрицу наблюдений\n","X = data['frame'].drop('target', axis=1)\n","# Создаем вектор правильных ответов\n","y = data['target']\n"," \n","X.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":598,"status":"ok","timestamp":1651231711495,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"krH5MCbUZudG","outputId":"83679799-49f8-4f7f-a821-bb0fd6300a9f"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Посмотрим на распределение целевого признака\n","y.hist();"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1651231711495,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"HCK1WLWKmaGB"},"outputs":[{"name":"stdout","output_type":"stream","text":["Размерность обучающей выборки (296, 10)\n","Размерность тестовой выборки (146, 10)\n"]}],"source":["# Разделим выборку на тренировочную и тестовую\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.33, random_state=42)\n","\n","# Посмотрим на размерности выборок\n","print(f'Размерность обучающей выборки {X_train.shape}')\n","print(f'Размерность тестовой выборки {X_test.shape}')"]},{"cell_type":"markdown","metadata":{"id":"YD4m3BKzzMQU"},"source":["## Бэггинг: случайный лес. \n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1651231711873,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"y7PWoTJqosJP","outputId":"dd9667dd-533e-42ec-e0c7-9fcec9e56114"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=10, random_state=42)</pre></div></div></div></div></div>"],"text/plain":["DecisionTreeRegressor(max_depth=10, random_state=42)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Создаем модель дерева решений с максимальной глубиной 10 \n","regr1 = DecisionTreeRegressor(max_depth=10, random_state=42)\n","# Обучаем модель\n","regr1.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651231711874,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"4Ds7ueJ6ma4c","outputId":"dfaa0511-b4af-4523-d4d8-1c398a24d0c6"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, n_estimators=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=10, n_estimators=10, random_state=42)</pre></div></div></div></div></div>"],"text/plain":["RandomForestRegressor(max_depth=10, n_estimators=10, random_state=42)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Создаем модель случайного леса из 10 деревьев с максимальной глубиной 10 для каждого дерева \n","regr2 = RandomForestRegressor(max_depth=10, n_estimators=10, random_state=42)\n","# Обучаем модель\n","regr2.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1651231711874,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"FDZzhjzIo3Bl","outputId":"41eb8bbb-b8f4-4b07-b0da-5c0bf3f605dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Качество предсказания по MSE для решающего дерева 6132.51\n","Качество предсказания по MSE для случайного леса  3533.73\n"]}],"source":["# Формируем предсказания каждой из моделей\n","y_pred1 = regr1.predict(X_test)\n","y_pred2 = regr2.predict(X_test)\n"," \n","# Оцениваем качество по метрике MSE\n","print(f'Качество предсказания по MSE для решающего дерева {round(mean_squared_error(y_test, y_pred1),2)}')\n","print(f'Качество предсказания по MSE для случайного леса  {round(mean_squared_error(y_test, y_pred2),2)}')"]},{"cell_type":"markdown","metadata":{"id":"K_debqSvzTRq"},"source":[" ## Стекинг"]},{"cell_type":"markdown","metadata":{},"source":["Стекинг (stacking) — алгоритм построения ансамбля, в котором параллельно и независимо друг от друга обучаются несколько базовых моделей (необязательно одной природы), а их предсказания используются для обучения метамодели (финальная модель) как факторы.\n","\n","Предсказания базовых алгоритмов называются метапризнаками. \n","\n","Простейшая реализация стекинга заключается в блендинге (blending). \n","\n","Суть блендинга состоит в следующем: предположим у нас есть обучающая выборка , которую мы делим пополам. Первая часть используется для обучения базовых моделей, а на второй базовые модели делают предсказания – метапризнаки, на которых уже и обучается в дальнейшем метамодель. \n","\n","Недостатки блендинга видны невооруженным глазом: ни базовые модели, ни метамодель не обучаются на полных данных. \n","\n","Для решения этой проблемы используется усовершенствованная модель блендинга, которая имеет полноценное название — стекинг. Идея борьбы с недостатком блендинга — использование кросс-валидации.\n","\n","Рассмотрим как обучается классический стекинг. Пусть у нас есть таблица с примерами X и ответами на них y. Количество признаков — m, количество наблюдений — n, количество моделей в стекинге — K.\n","\n","1. Обучающая выборка разбивается на L равных частей, называемых фолдами. \n","2. Затем для каждой базовой модели эти фолды перебираются следующим образом: на каждом шаге фиксируются L-1 фолдов для обучения базовых моделей и один фолд для предсказания (в случае бинарной классификации каждая модель предсказывает вероятность принадлежности к классу 1, в случае мультиклассовой классификации — к каждому классу). В результате будет сформировано L предсказаний, из которых формируется метапризнак Mj, где j — номер модели.\n","Такой подход к формированию метапризнаков позволяет избежать переобучения. Действительно, можно рассматривать L-1 фолд как обучающую выборку, а оставшийся — как тестовую. Таким образом, мы обучаемся на тренировочной выборке, но предсказания делаем для той выборки, которую ещё не видели.\n","\n","3. После того как мы проделаем шаг 2 для всех базовых моделей, мы получим новый набор данных, состоящий из  метапризнаков — предсказаний каждой из моделей. Предсказания моделей будут использоваться в качестве метапризнаков, на которых будет обучена метамодель."]},{"cell_type":"markdown","metadata":{},"source":["Давайте посмотрим, как работает алгоритм на конкретной таблице. Пусть у нас есть некоторый набор данных из четырёх признаков, характеризующих клиента (x_0, x_1, x_2 и x_3), и восемь наблюдений. На основе этих признаков необходимо предсказать бинарный целевой признак (y) покупки товара со значениями 1 (купил) и 0 (не купил). Будем использовать стекинг, состоящий из трёх различных моделей.\n","\n","Разбиваем выборку на четыре фолда, то есть в каждом фолде будет по две строки таблицы (обозначены цветом). Обучаем каждую модель на трёх из этих фолдов и делаем предсказание вероятности покупки для оставшегося.\n","\n","Из предсказаний будет сформировано три метапризнака (по одному на каждую базовую модель). Это будут предсказанные базовыми классификаторами вероятности покупки (вероятность принадлежности к классу 1).\n","\n","dst3-ml3-8_4.png --> dst3-ml3-8_5.png"]},{"cell_type":"markdown","metadata":{},"source":["Важно понимать, стекинг — это чистая эвристика, эффективность которой доказана только практическим применением. Стекинг использует тот же подход, что и нейронные сети: предсказания предыдущего этапа (слоя) используются в качестве признаков для следующего этапа (слоя).\n","\n","С точки зрения смещения и разброса, стекинг не имеет прямой математической интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, но гарантий уменьшения смещения или разброса нет.\n","\n","Есть некоторые рекомендации, как правильно строить стекинг:\n","- В качестве метамоделей лучше всего применять простые модели: например, для задачи регрессии — линейную регрессию, а для задачи классификации — логистическую регрессию.\n","- В качестве базовых моделей лучшего всего использовать модели различной природы.\n","\n","Из всех ансамблевых методов стекинг применяется реже всего. Главная причина: так как используется много разных моделей, необходимо подбирать их внешние параметры (коэффициенты регуляризации, глубина деревьев, число деревьев, темп обучения и т. д.) в совокупности, а подбор огромного количества параметров очень затратен по времени (мы убедились в этом в модуле по подбору внешних параметров моделей).\n","\n","Вторая причина — в отличие от бэггинга и бустинга, для стекинга нет каких-то готовых решений, таких как случайный лес и градиентный бустинг над деревьями. Базовые модели нужно подбирать самому, а какие из них подойдут лучше всего — открытый вопрос.\n","Но, несмотря на эти недостатки, при грамотном подходе опытные специалисты выигрывают соревнования на Kaggle благодаря стекингу. Хотя зачастую таких участников называют «читерами» (от англ. cheat — «жульничать, обманывать»), ведь часто они собирают чуть ли не все возможные ML-модели в стекинг, запускают на мощном сервере подбор внешних параметров и комбинации из этих моделей в стекинге получают заветные 1.5 % прироста качества модели. На Kaggle даже существует фраза — «настекали».\n","\n","В реальных условиях такой прирост значит мало, поэтому мы не будем концентрироваться на стекинге в нашем курсе, но пример разберём."]},{"cell_type":"markdown","metadata":{},"source":["Стекинг для задачи регрессии имеет реализацию в библиотеке scikit-learn в классе StackingRegressor, для задачи классификации — в классе StackingClassifier. На вход подаётся список базовых моделей (атрибут estimators) и метамодель (атрибут final_estimator).\n","\n","Примечание. Стоит понимать, что для задачи регрессии все базовые модели должны быть регрессорами, а для задачи классификации — классификаторами.  \n","\n","Попробуем на практике применить стекинг, используя реализацию из библиотеки sklearn. В качестве входных данных будем использовать данные про диабет, использованные ранее. Обратимся снова к коду и обучим модель на данных.\n","\n","Как и все ансамбли, модель стекинга находится в модуле ensemble."]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1651231712267,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"n8b_avQa1Hor"},"outputs":[],"source":["from sklearn.ensemble import StackingRegressor\n","from sklearn.linear_model import RidgeCV"]},{"cell_type":"markdown","metadata":{},"source":["Основные параметры StackingRegressor:\n","\n","- estimators — список из кортежей базовых моделей в виде (str, model). Первым элементом в каждом кортеже идет строка с именем модели, вторым — собственно сама модель.\n","- final_estimator — метамодель.\n","- cv — количество фолдов, на которые делится выборка. По умолчанию используется пять фолдов.\n","\n","Будем строить стекинг на следующих моделях:\n","- 'dt' — дерево решений;\n","- 'lr' — ридж-регрессия, линейная модель регрессии с L2-регуляризацией;\n","- случайный лес с количеством деревьев, равным 10, в качестве метамодели.\n","\n","Примечание. В данном случае мы рассматриваем RidgeCV, которая представляет собой ридж-регрессию со встроенной кросс-валидацией по методу Leave-One-Out Cross-Validation. Подробнее читайте по ссылке.\n","\n","Создадим список кортежей в формате (\"наименование модели\", модель) из этих моделей, и назовем его estimators:"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1651231713053,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"cnXnx74upHAH","outputId":"8d729fd1-e121-49e1-8a18-346cbe66169b"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;lr&#x27;, RidgeCV()),\n","                              (&#x27;dt&#x27;, DecisionTreeRegressor(random_state=42))],\n","                  final_estimator=RandomForestRegressor(n_estimators=10,\n","                                                        random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;lr&#x27;, RidgeCV()),\n","                              (&#x27;dt&#x27;, DecisionTreeRegressor(random_state=42))],\n","                  final_estimator=RandomForestRegressor(n_estimators=10,\n","                                                        random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>dt</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=10, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["StackingRegressor(estimators=[('lr', RidgeCV()),\n","                              ('dt', DecisionTreeRegressor(random_state=42))],\n","                  final_estimator=RandomForestRegressor(n_estimators=10,\n","                                                        random_state=42))"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Создаем список кортежей вида: (наименование модели, модель)\n","estimators = [\n","    ('lr', RidgeCV()),\n","    ('dt',  DecisionTreeRegressor(random_state=42))\n","]\n","\n","# Теперь, когда список из базовых моделей готов, создадим объект класса StackingRegressor. \n","# Первым аргументом передаём список из базовых моделей. Будем использовать в качестве метамодели модель случайного леса. \n","# Для этого передаём её в параметр final_estimator. Остальные параметры оставим по умолчанию.\n","\n","# Обучаем модель с помощью метода fit(), делаем предсказание классов с помощью метода predict(), а затем считаем метрики:\n","# Создаем объект класса стекинг\n","reg = StackingRegressor(\n","    estimators=estimators,\n","    final_estimator=RandomForestRegressor(n_estimators=10,\n","                                          random_state=42)\n",")\n","# Обучаем модель\n","reg.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1651231713459,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"0qvtPD_B1Nfy","outputId":"6d7f0835-f46e-48c7-8205-e6a960e5c952"},"outputs":[{"name":"stdout","output_type":"stream","text":["Качество предсказания по MSE для стекинга 3467.74\n"]}],"source":["# Формируем предсказание для тестовой выборки\n","y_pred_stack = reg.predict(X_test)\n","# Оцениваем качество по метрике MSE\n","print(f'Качество предсказания по MSE для стекинга {round(mean_squared_error(y_test, y_pred_stack), 2)}')"]},{"cell_type":"markdown","metadata":{},"source":["Посмотреть на метапризнаки можно с помощью метода transform(). Для этого в метод нужно передать матрицу наблюдений X. В результате вызова метода для всех объектов каждая из двух моделей сделает предсказание вероятностей и вернёт матрицу из двух столбцов. Оформим её в виде DataFrame:"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1651231713886,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"sV-gKlT91RzF","outputId":"676022b8-9f65-4c7e-cfc7-591a006a051a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>meta_feature1</th>\n","      <th>meta_feature2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>152.477333</td>\n","      <td>154.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>202.022338</td>\n","      <td>192.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>133.718464</td>\n","      <td>116.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>146.698345</td>\n","      <td>81.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>169.783292</td>\n","      <td>122.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   meta_feature1  meta_feature2\n","0     152.477333          154.0\n","1     202.022338          192.0\n","2     133.718464          116.0\n","3     146.698345           81.0\n","4     169.783292          122.0"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Получаем мета-признаки из тренировочных данных\n","meta_data = reg.transform(X_train)\n","# Создаем DataFrame\n","meta_df = pd.DataFrame(\n","    meta_data, #содержимое таблицы\n","    columns=['meta_feature1', 'meta_feature2',] #название столбцов\n",")\n","meta_df.head()"]},{"cell_type":"markdown","metadata":{"id":"aw6T7BsNElcq"},"source":[" ## Бустинг\n"," \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Бустинг (boosting) — это алгоритм построения ансамбля, основанный на последовательном построении слабых моделей, причём каждая новая модель пытается уменьшить ошибку предыдущей. После того как все модели обучены, они объединяются в композицию.\n","\n","Примечание. Под слабыми моделями мы подразумеваем модели, точность которых немногим выше, чем случайное угадывание. Как правило, это короткие деревья решений, они обладают слабой предсказательной способностью.\n","\n","Обратите внимание, что в бустинге базовые модели обучаются последовательно, а не параллельно, как в предыдущих методах, исправляя ошибки своего «предшественника»  и повышая качество всего ансамбля. \n","\n","Бустинг основан на вопросе, поднятом исследователями М. Кернсом и Л. Вэлиантом: «Может ли набор слабых обучающих алгоритмов создать сильный обучающий алгоритм?»\n","\n","В отличие от бэггинга, бустинг обучается на одном и том же наборе данных, без генерации дополнительных выборок. Однако в процессе обучения меняются так называемые веса наблюдений. Если слабая модель допустила ошибку на каких-то примерах, то значимость (вес) этих примеров увеличивается и на них концентрируется следующая за ней модель.\n","\n","**Так же как и бэггинг, бустинг предназначен для обучения моделей одного типа. То есть нельзя последовательно обучить 50 логистических регрессий, а затем 50 деревьев решения.**\n","\n","Каждая модель создаётся для того, чтобы найти ошибки предыдущей. Сами по себе они решают задачу плохо, но стоит объединить их усилия, и мы получим супермодель.\n","\n","*Примечание*. Когда все модели из ансамбля обучены и составлена композиция из них, для того, чтобы совершить предсказание на новом объекте, необходимо «прогнать» характеристики объекта через все модели в той же последовательности, в которой они обучались, и объединить их результат.\n","\n","Если бэггинг создавался с целью уменьшить разброс модели, то цель бустинга — уменьшить смещение модели.\n","\n","Каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников. Как следствие, итоговая композиция будет иметь меньшее смещение, чем каждый отдельный базовый алгоритм (хотя уменьшение разброса также может происходить).\n","\n","В предельном случае модель может обучиться так, что не будет допускать ошибок вовсе. Однако мы знаем, что это не всегда хорошо, ведь в таком случае модель может полностью подстроиться под обучающий набор данных и переобучиться.\n","Поскольку основная цель бустинга — уменьшение смещения, в качестве базовых моделей часто выбирают алгоритмы с высоким смещением и небольшим разбросом, например короткие деревья решений. У каждого из таких деревьев слабая предсказательная способность, но если их объединить, мы получим очень мощную модель. \n","\n","В этом юните мы постараемся затронуть основные шаги эволюции бустинга от первой успешной модели до современных модификаций. Начнём рассмотрение с самой первой модели бустинга — адаптивного бустинга."]},{"cell_type":"markdown","metadata":{"id":"5_kA1uXbLhZo"},"source":["### Адаптивный бустинг"]},{"cell_type":"markdown","metadata":{},"source":["Первая реализация бустинга называлась AdaBoost. Это модель, которая подразумевает воплощение той самой идеи взвешивания объектов, которую мы рассмотрели выше. Алгоритм предполагает постоянную модификацию объектов выборки путём их взвешивания, причём веса обновляются специальным образом: каждая новая модель из ансамбля обучается на взвешенных данных и обращает большее внимание на ошибки своих предшественников.\n","\n","Так как алгоритм является несовершенным и в дальнейшем получил свое развитие, мы не будем подробно останавливаться на его работе. Однако приведем краткое описание работы алгоритма на примере задачи бинарной классификации. \n","\n","Пусть у нас есть набор данных X, в котором N объектов размерности m (вектора в признаковом пространстве размера M) и метки класса y∈−1,1, где -1 и 1 — метки отрицательного и положительного класса соответственно.\n","\n","Будем строить ансамбль из K абстрактных базовых моделей — классификаторов. Обозначим их как a(x) (это могут быть логистические регрессии/деревья решений или что-то ещё).  \n","\n","В чём плюсы такого алгоритма?\n","\n","✔️ Он прост. Обратите внимание: все математические операции — школьный курс математики, о высшей математике даже не идёт речи. Операции просты в реализации и не требуют вычисления производных, умножений матриц и прочих сложных математических конструкций.\n","\n","✔️ Накладные расходы бустинга минимальны. Время построения определяется временем построения базовых моделей.\n","\n","✔️ Показывает хорошую обобщающую способность.\n","\n","✔️ Имеет возможность идентификации шумовых объектов в ряде случаев.\n","\n","Но в чём минусы?\n","\n","⛔️ Жадное добавление алгоритмов приводит к неоптимальности композиции.\n","\n","⛔️ Склонен к переобучению при наличии шума в данных.\n","\n","⛔️ Алгоритм является эвристикой, и «взвешивание» объектов, на котором он основан, не подкреплено математическим обоснованием."]},{"cell_type":"markdown","metadata":{},"source":["В sklearn адаптивный бустинг над решающими деревьями реализован в модуле sklearn.ensemble в виде классов AdaBoostRegressor и AdaBoostClassifier для задач регрессии и классификации соответственно. Давайте проведём обучение на тех же данных, что и в предыдущих моделях ансамблирования — на данных о диабете. \n","\n","Прежде чем перейти к практической части, предлагаем ознакомиться с параметрами AdaBoost:\n","- estimator — параметр отвечает за природу базовых моделей, по умолчанию это DecisionTreeRegressor c максимальной глубиной (max_depth) 3.\n","- n_estimators — максимальное количество базовых моделей, по умолчанию равно 50. В случае идеального обучения алгоритм завершается ранее, чем данное значение.\n","- learning_rate — темп обучения, параметр, добавляющий дополнительный множитель весу базовой модели, по умолчанию он равен 1.\n","- loss{'linear', 'square', 'exponential'} — функция ошибки для обновления весов (в теоретической части мы рассматривали экспоненциальную форму обновления весов — 'exponential')\n","- random_state — параметр, фиксирующий случайные процессы в модели.\n","\n","Для сравнимости результатов со случайным лесом возьмём количество базовых моделей, равное 10. Как говорилось ранее, глубина деревьев должна быть меньше, чем у случайного леса. По умолчанию она равна 3.  "]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1651231761534,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"jUeiJ1O8FQli","outputId":"74a57c13-cdfa-4b35-f1e2-fab9f1654a6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Качество предсказания по MSE для AdaBoost 3040.83\n"]}],"source":["from sklearn.ensemble import AdaBoostRegressor\n","\n","# Создаем объект класса дерева решений\n","dt = DecisionTreeRegressor(\n","    max_depth=3, #максимальная глубина дерева\n","    random_state=42 #датчик генератора случайных чисел\n",")\n","# Создаем объект класса AdaBoost\n","ada = AdaBoostRegressor(\n","    estimator=dt, #базовая модель\n","    n_estimators=10, #количество моделей в ансамбле\n","    random_state=42 #датчик генератора случайных чисел\n",")\n","# Обучаем модель\n","ada.fit(X_train, y_train)\n","\n","# Формируем предсказание для тестовой выборки\n","ada_pred  = ada.predict(X_test)\n","\n","# Оцениваем качество по метрике MSE\n","print(f'Качество предсказания по MSE для AdaBoost {round(mean_squared_error(y_test, ada_pred),2)}')\n"]},{"cell_type":"markdown","metadata":{"id":"6w1idgnvHKax"},"source":["### Градиентный бустинг (регрессия)"]},{"cell_type":"markdown","metadata":{},"source":["Градиентный бустинг (Gradient Boosting, GB) — это наиболее обобщённая версия бустинга, закреплённая математическим обоснованием. Впервые алгоритм был опубликован профессором статистики Стэнфордского университета Джеромом Фридманом. Алгоритм оказался очень эффективным и в дальнейшем был множество раз модифицирован — до Extreme Gradient Boosting (XgBoost) и других модификаций, таких как CatBoost от Яндекса и LightGMB от Microsoft.\n","\n","Сейчас градиентный бустинг и его модификации применяются практически везде. Любой запрос на Яндексе, выбор отеля на Booking или сериала на Netflix — всё это работает на градиентном бустинге. \n","\n","→ В этом модуле мы кратко рассмотрим принцип работы, а в модулях по математике разберём математическую формализацию алгоритма. \n","\n","В GB принцип классического бустинга сохраняется: каждый последующий алгоритм улучшает предыдущий, но, в отличие эвристического «взвешивания» наблюдений, градиентный бустинг использует информацию о функции потерь для построения нового алгоритма. "]},{"cell_type":"markdown","metadata":{},"source":["Бустинг, использующий в качестве базовой модели дерево решений, называется градиентным бустингом над деревьями решений (Gradient Boosting on Decision Trees, GBDT). \n","\n","Основным преимуществом такой схемы градиентного бустинга является эффективность в поиске нелинейных зависимостей в сравнении с любыми моделями, основанными на решающих деревьях. Это преимущество стало причиной доминирования GBDT на огромном спектре соревнований — от кредитного скоринга до рекомендательных систем.\n","\n","В заключение введения в градиентный бустинг приведём некоторые рекомендации по выбору внешних параметров алгоритма:\n","- Количество деревьев (n_estimators). Чем больше деревьев вы берёте, тем меньше ошибка на обучающем наборе данных, вплоть до 0, но, как вы понимаете, тем выше шанс переобучиться. Лучше начинать с небольшого количества моделей (50-100), а затем следить за ошибкой на тестовой выборке.\n","- Темп обучения  (learning_rate). Чем выше темп обучения, тем больше вклад каждого следующего дерева будет в модель и тем быстрее вы сойдётесь к минимуму функции потерь и сведёте ошибку к 0. Однако снова высок риск переобучения. Рекомендуемые значения — от 0.01 до 1.\n","- Максимальная глубина деревьев (max_depth). Градиентный бустинг лучше всего работает со слабыми моделями — это короткие деревья решений с глубиной от 1 до 8.\n","\n","→ Все параметры влияют на обучение комплексно, поэтому их следует подбирать одновременно. О том, какие инструменты для этого существуют, мы поговорим в отдельном модуле.\n","\n","Чтобы понять, как на градиентный бустинг влияют параметры темпа обучения, максимальной глубины деревьев и количества деревьев, предлагаем вам поиграть с настройками градиентного бустинга интерактивной демонстрации Brilliantly wrong.\n","\n","Вы можете регулировать следующие параметры:\n","- tree depth — максимальная глубина деревьев;\n","- learning rate — темп обучения;\n","- subsample — процент выборки, отведённый на обучение;\n","- trees — количество деревьев.\n","\n","На демонстрации вы сможете увидеть, как меняется функция ошибки на тренировочной (train loss) и тестовой (test loss) выборках при изменении параметров, а также как меняется вид разделяющей поверхности."]},{"cell_type":"markdown","metadata":{},"source":["Как и все ансамбли, градиентный бустинг находится в модуле ensemble библиотеки sklearn. В качестве входных данных продолжим использовать данные о диабете.\n","\n"," Градиентный бустинг над деревьями для решения задачи регрессии реализован в классе GradientBoostingRegressor. Для задачи классификации данный метод реализован в классе GradientBoostingClassifier. Параметры у классов схожи, различия только в функции потерь. Поэтому мы можем рассмотреть параметры GradientBoostingRegressor, подразумевая, что у классификатора они идентичны.\n","\n","Основные параметры GradientBoostingRegressor:\n","- loss — функция потерь. По умолчанию в регрессии 'squared_loss' - наша любимая MSE, а в классификации 'log_loss' - логистическая функция потерь.\n","- learning_rate — темп обучения. По умолчанию 0.1. \n","- n_estimators — количество деревьев в бустинге (число K из бустинга). По умолчанию равно 100.\n","- max_depth — максимальная глубина одного дерева. По умолчанию равна 3 — строятся короткие деревья с большим смещением.\n","- min_samples_leaf — минимальное число объектов в листе. По умолчанию 1.\n","- random_state — число, отвечающее за генерацию случайных чисел."]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":407,"status":"ok","timestamp":1651233371648,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"kAKJpZTgGMA6","outputId":"8a670a9c-eae2-4ddc-b2e2-901f4530c829"},"outputs":[{"name":"stdout","output_type":"stream","text":["Качество предсказания по MSE для GradientBoostingRegressor 3477.3\n"]}],"source":["from sklearn.ensemble import GradientBoostingRegressor\n","\n","# Создаем объект класса градиентный бустинг\n","gb = GradientBoostingRegressor(\n","    max_depth=3, #максимальная глубина дерева\n","    n_estimators=10, #количество деревьев в ансамбле\n","    random_state=42 #датчик генератора случайных чисел\n",")\n","\n","# Обучаем модель\n","gb.fit(X_train, y_train)\n","\n","# Формируем предсказание для тестовой выборки\n","gb_pred  = gb.predict(X_test)\n","\n","# Оцениваем качество по метрике MSE\n","print(f'Качество предсказания по MSE для GradientBoostingRegressor {round(mean_squared_error(y_test, gb_pred),2)}')"]},{"cell_type":"markdown","metadata":{},"source":["Из полученных в предыдущем задании результатов видно, что повысить качество ансамбля моделей можно, увеличив количество моделей в ансамбле. Однако важно понимать, что зависимость качества ансамбля от количества моделей является нелинейной. При большом количестве моделей градиентный бустинг может уходить в переобучение, тем самым ухудшая метрики на тестовой выборке.\n","\n","Основной фактор, влияющий на зависимость качества ансамбля от количества моделей в нем — сложность исходных данных."]},{"cell_type":"markdown","metadata":{"id":"dWY3VF6UC1JP"},"source":["### Градиентный бустинг (классификация)"]},{"cell_type":"markdown","metadata":{},"source":["✍️ Попробуем решить задачу бинарной классификации с помощью градиентного бустинга. Для этого возьмём датасет качества вина. В качестве целевой метки будем считать качественным вино, рейтинг которого больше пяти."]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1651233530673,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"qoucUy0aHXdE"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":513,"status":"ok","timestamp":1651233561300,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"2AMYj0npC7jK"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed acidity</th>\n","      <th>volatile acidity</th>\n","      <th>citric acid</th>\n","      <th>residual sugar</th>\n","      <th>chlorides</th>\n","      <th>free sulfur dioxide</th>\n","      <th>total sulfur dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","      <th>quality</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.8</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>2.6</td>\n","      <td>0.098</td>\n","      <td>25.0</td>\n","      <td>67.0</td>\n","      <td>0.9968</td>\n","      <td>3.20</td>\n","      <td>0.68</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.8</td>\n","      <td>0.76</td>\n","      <td>0.04</td>\n","      <td>2.3</td>\n","      <td>0.092</td>\n","      <td>15.0</td>\n","      <td>54.0</td>\n","      <td>0.9970</td>\n","      <td>3.26</td>\n","      <td>0.65</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.2</td>\n","      <td>0.28</td>\n","      <td>0.56</td>\n","      <td>1.9</td>\n","      <td>0.075</td>\n","      <td>17.0</td>\n","      <td>60.0</td>\n","      <td>0.9980</td>\n","      <td>3.16</td>\n","      <td>0.58</td>\n","      <td>9.8</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n","0            7.4              0.70         0.00             1.9      0.076   \n","1            7.8              0.88         0.00             2.6      0.098   \n","2            7.8              0.76         0.04             2.3      0.092   \n","3           11.2              0.28         0.56             1.9      0.075   \n","4            7.4              0.70         0.00             1.9      0.076   \n","\n","   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n","0                 11.0                  34.0   0.9978  3.51       0.56   \n","1                 25.0                  67.0   0.9968  3.20       0.68   \n","2                 15.0                  54.0   0.9970  3.26       0.65   \n","3                 17.0                  60.0   0.9980  3.16       0.58   \n","4                 11.0                  34.0   0.9978  3.51       0.56   \n","\n","   alcohol  quality  \n","0      9.4        5  \n","1      9.8        5  \n","2      9.8        5  \n","3      9.8        6  \n","4      9.4        5  "]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["# Читаем исходные данные к задаче классификации\n","df = pd.read_csv('data/winequality-red.csv', sep = ';')\n","df.head(5)"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":396,"status":"ok","timestamp":1651233623470,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"AMNxX6jzdXvv"},"outputs":[],"source":["# Создаем матрицу наблюдений \n","X = df.drop(['quality'],axis = 1)\n","# Создаем вектор признаков для бинарной классификации\n","y = (df['quality'] >5).astype(int)"]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1651233623854,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"DYvtoqandq3I"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Размерность обучающей выборки (1071, 11)\n"," Размерность тестовой выборки (528, 11)\n"]}],"source":["# Разделим выборку на тренировочную и тестовую\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.33, random_state=42)\n","# Посмотрим на размерности выборок\n","print(f' Размерность обучающей выборки {X_train.shape}')\n","print(f' Размерность тестовой выборки {X_test.shape}')"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1312,"status":"ok","timestamp":1651233771011,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"tgK2bX4RdPG0","outputId":"e03e706f-c215-4f51-c368-405d06fb4c94"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.76      0.77      0.77       238\n","           1       0.81      0.80      0.81       290\n","\n","    accuracy                           0.79       528\n","   macro avg       0.79      0.79      0.79       528\n","weighted avg       0.79      0.79      0.79       528\n","\n"]}],"source":["# Создаем модель градиентного бустинга\n","gb = GradientBoostingClassifier(\n","    loss='log_loss', #функция потерь\n","    learning_rate=0.1, #темп обучения\n","    n_estimators=100, #число деревьев\n","    max_depth=3, #максимальная глубина дерева\n","    random_state=42 #генератор случайных чисел\n",")\n","# Обучаем модель\n","gb.fit(X_train, y_train)\n","# Формируем предсказание для тестовой выборки\n","y_pred = gb.predict(X_test)\n","# Посмотрим на основные метрики классификации\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1651233779804,"user":{"displayName":"Андрей Рысистов","userId":"06358684909149003375"},"user_tz":-180},"id":"m-L3vU9Bd4CZ","outputId":"867bfab9-d72d-4895-983f-a5ee174154d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.7575177  0.2424823 ]\n"," [0.81931477 0.18068523]\n"," [0.80325657 0.19674343]\n"," ...\n"," [0.0212709  0.9787291 ]\n"," [0.90355559 0.09644441]\n"," [0.80946194 0.19053806]]\n"]}],"source":["# Прогнозируем вероятности принадлежности к классам\n","y_pred_proba = gb.predict_proba(X_test)\n","print(y_pred_proba)"]},{"cell_type":"markdown","metadata":{},"source":["Известно, что с уменьшением темпа обучения (learning_rate) возникает необходимость повышения количества базовых моделей, то есть существует некоторая дилемма (trade-off) между темпом обучения и количеством моделей (n_estimators). Посмотрим на практике, как эти параметры связаны между собой. "]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.78      0.76      0.77       238\n","           1       0.81      0.83      0.82       290\n","\n","    accuracy                           0.80       528\n","   macro avg       0.79      0.79      0.79       528\n","weighted avg       0.80      0.80      0.80       528\n","\n"]}],"source":["# Создаем модель градиентного бустинга\n","gb = GradientBoostingClassifier(\n","    loss='log_loss', #функция потерь\n","    learning_rate=0.2, #темп обучения\n","    n_estimators=500, #число деревьев\n","    max_depth=3, #максимальная глубина дерева\n","    min_samples_leaf=10,\n","    random_state=42 #генератор случайных чисел\n",")\n","# Обучаем модель\n","gb.fit(X_train, y_train)\n","# Формируем предсказание для тестовой выборки\n","y_pred = gb.predict(X_test)\n","# Посмотрим на основные метрики классификации\n","print(classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["⭐️ Поздравляем! Мы разобрали практически все ныне существующие методы ансамблирования — от самых простых, которые легли в основу случайного леса, до самых передовых (градиентных бустингов). Мы посмотрели на реализации в библиотеке sklearn, постарались разобрать методологию и основные параметры каждой модели. \n","\n","Основными рекомендациями по использованию ансамблей является использование случайных лесов и градиентных бустингов в первую очередь для классических задач классификации и регрессии с простыми табличными данными, так как подавляющее большинство соревнований в этой области было выиграно именно благодаря этим двум моделям. \n","\n","После данного модуля может сложиться впечатление, что ансамблирование — всегда лучший вариант для финальной модели, однако часто в задачах требуется интерпретируемость результатов, которой не могу похвастаться бустинг и стекинг. \n","\n","Кроме того, использование случайного леса на данных с большим количеством выбросов может привести к тому, что модель будет обучается на данных, у которых дисперсия в разы больше, чем у исходных, так как подвыборка для обучения выбирается случайно. Таким образом, мы не сможем получить выигрыш в дисперсии, который нам даёт ансамблирование. \n","\n","В заключение приведём таблицу преимуществ и недостатков методов ансамблирования:\n","\n","\n","**Бэггинг**\\\n","✔️ Плюсы\n","- Хорошо параллелится вычисление (модели обучаются параллельно)\n","- Снижает дисперсию\n","\n","⛔ Минусы\n","- Предполагается использование одинаковых моделей\n","- Необходимо использование глубоких деревьев\n","- Плохо интерпретируемая\n","\n","**Стекинг**\\\n","✔️ Плюсы\n","- Хорошо параллелится (модели обучаются параллельно)\n","- Хорош для использования различных по природе базовых моделей\n","\n","⛔ Минусы\n","- Качество сильно зависит от качества базовых моделей\n","- Плохо интерпретируемая\n","\n","**Бустинг**\\\n","✔️ Плюсы\n","- Модели обучаются последовательно, уточняя друг друга\n","- Снижает смещение\n","- Базовые модели — неглубокие деревья\n","\n","⛔ Минусы\n","- Плохо параллелится вычисление\n","- Плохо интерпретируемая\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ML-8. Ensembles.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"vscode":{"interpreter":{"hash":"86c56a74836ad344b00594bf6f38fa6a676a207ceefe20d101fbc465800ccb8d"}}},"nbformat":4,"nbformat_minor":0}
