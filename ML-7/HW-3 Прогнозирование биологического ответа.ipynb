{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные моделиё\n",
    "from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считывем данные из файла\n",
    "data = pd.read_csv('data/train_sem09.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверяем данные на сбалансированность классов\n",
    "sns.countplot(data=data, x='Activity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n",
    "\n",
    "В качестве метрики будем использовать F1-score.\n",
    "\n",
    "Необходимо обучить две модели: \n",
    "- логистическую регрессию\n",
    "- случайный лес. \n",
    "\n",
    "Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем матрицу наблюдений Х и вектор ответов у\n",
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем выборку на тренировочную и тестовую в соотношении 80/20. \n",
    "# Т.к. в данных есть небольшое преобладание класса 1, то для сохранения соотношений целевого признака используем параметр stratify. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 1, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Логистическая регрессия\n",
    "Сначала обучим модель логистической регрессии и подберем для нее гиперпараметры с помощью базовых и продвинутых методом оптимизации.\n",
    "\n",
    "Зафиксируем метрики, которые были получены без дополнительной настройки, т.е со значениями гиперпараметров, установленных по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса логистическая регрессия\n",
    "log_reg = linear_model.LogisticRegression(max_iter = 1000)\n",
    "#Обучаем модель, минимизируя logloss\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(log_reg.score(X_test, y_test)))\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.44 s, sys: 918 ms, total: 4.36 s\n",
      "Wall time: 4min 52s\n",
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=50), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Использование GridSearchCV позволило увеличить нашу метрику F1 с 0.78 до 0.79**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение точности при кросс-валидаци: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшее значение точности при кросс-валидаци: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# отрисуем, как менялась точность при различных гиперпараметрах\n",
    "visual = pd.pivot_table(pd.DataFrame(grid_search.cv_results_),\n",
    "                        values='mean_test_score', index='param_C',\n",
    "                        columns='param_solver')\n",
    "sns.heatmap(visual)\n",
    "plt.title('Тепловая карта зависимости метрики accuracy от solver и С') # подпись графика\n",
    "sns.set(rc={'figure.figsize':(12, 8)}) #задаем размер графика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что слабая регуляризация С = 0,01 отрицательно влияет на метрику, поэтому есть смысл брать значения больше 0,5 и алгоритм оптимизации saga работает намного лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.751      0.759      0.75333333 0.75733333 0.75033333        nan\n",
      " 0.75133333 0.754             nan 0.755     ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.82 s, sys: 245 ms, total: 4.06 s\n",
      "Wall time: 58.5 s\n",
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'solver': 'saga', 'penalty': 'l2', 'C': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "              'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'lbfgs', 'saga', 'sag'],\n",
    "               'C': list(np.linspace(0.01, 1, 10, dtype=float))\n",
    "               }          \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=50), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5, \n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search.score(X_test, y_test)))\n",
    "y_test_pred = random_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Использование RandomizedSearchCV также позволило увеличить нашу метрику F1 с 0.78 до 0.79**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperopt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={'penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "       'solver' : hp.choice('solver', ['liblinear', 'saga']),\n",
    "       'C': hp.uniform('C', low=0.01, high=1)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_Log_reg(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty': params['penalty'], \n",
    "              'solver': params['solver'], \n",
    "             'C': params['C']\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return {'loss': -score, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:12<05:46,  7.22s/trial, best loss: -0.8760330578512396]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:23<04:57,  6.47s/trial, best loss: -0.8760330578512396]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:30<03:52,  5.28s/trial, best loss: -0.8760330578512396]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:37<04:10,  5.83s/trial, best loss: -0.8760330578512396]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:51<03:46,  5.67s/trial, best loss: -0.8807339449541284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:58<03:08,  4.95s/trial, best loss: -0.8807339449541284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [01:11<03:34,  5.95s/trial, best loss: -0.8807339449541284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [01:22<04:27,  7.64s/trial, best loss: -0.8807339449541284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [01:31<03:24,  6.19s/trial, best loss: -0.8850855745721271]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [01:40<03:54,  7.33s/trial, best loss: -0.8850855745721271]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [01:52<04:25,  8.56s/trial, best loss: -0.8850855745721271]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [02:16<00:18,  2.58s/trial, best loss: -0.8856968215158926]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [02:25<00:13,  3.43s/trial, best loss: -0.8856968215158926]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [02:33<00:07,  3.92s/trial, best loss: -0.8856968215158926]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:41<00:00,  3.24s/trial, best loss: -0.8856968215158926]\n",
      "Наилучшие значения гиперпараметров {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9985710176440787}\n",
      "CPU times: user 2min 34s, sys: 3.25 s, total: 2min 38s\n",
      "Wall time: 2min 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_Log_reg, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=50, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(trials.best_trial['result']['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.89\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = linear_model.LogisticRegression(\n",
    "    random_state=random_state, \n",
    "    penalty=trials.best_trial['result']['params']['penalty'],\n",
    "    solver=trials.best_trial['result']['params']['solver'],\n",
    "    C=trials.best_trial['result']['params']['C']\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Использование Hyperopt не улучшило нашу метрику, F1 = 0.78**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_log_reg(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "  solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "  C = trial.suggest_float('C', low=0.01, high=1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = linear_model.LogisticRegression(penalty=penalty,\n",
    "                                          solver=solver,\n",
    "                                          C=C,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 20:44:44,951] A new study created in memory with name: LogisticRegression\n",
      "[I 2024-05-10 20:44:45,787] Trial 0 finished with value: 0.8148371531966225 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.1887877022256806}. Best is trial 0 with value: 0.8148371531966225.\n",
      "[I 2024-05-10 20:44:47,124] Trial 1 finished with value: 0.8661369193154035 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.9399811941811593}. Best is trial 1 with value: 0.8661369193154035.\n",
      "[I 2024-05-10 20:44:47,738] Trial 2 finished with value: 0.8677054689886954 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.3262336846102354}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:44:48,339] Trial 3 finished with value: 0.8674404398289554 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.30615749050186275}. Best is trial 2 with value: 0.8677054689886954.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:44:55,961] Trial 4 finished with value: 0.8658536585365855 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.28549639821646594}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:44:56,430] Trial 5 finished with value: 0.8186746987951808 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.23512261895071132}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:44:58,140] Trial 6 finished with value: 0.8675435913123279 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.9724843151463165}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:44:58,737] Trial 7 finished with value: 0.8660360085444003 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.2520952819503368}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:44:59,324] Trial 8 finished with value: 0.8674404398289554 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.307990247329825}. Best is trial 2 with value: 0.8677054689886954.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:45:09,043] Trial 9 finished with value: 0.7939939939939942 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.08632697281243361}. Best is trial 2 with value: 0.8677054689886954.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:45:16,123] Trial 10 finished with value: 0.8670131458269642 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.601234433904303}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:45:16,954] Trial 11 finished with value: 0.8594940566900335 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.6934499700973973}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:45:18,138] Trial 12 finished with value: 0.8675435913123279 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.9775618862243621}. Best is trial 2 with value: 0.8677054689886954.\n",
      "[I 2024-05-10 20:45:18,839] Trial 13 finished with value: 0.8714023270055115 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.45048440460862893}. Best is trial 13 with value: 0.8714023270055115.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:45:25,478] Trial 14 finished with value: 0.8660550458715596 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.47612593740225073}. Best is trial 13 with value: 0.8714023270055115.\n",
      "[I 2024-05-10 20:45:26,200] Trial 15 finished with value: 0.8725490196078431 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.4705648019346566}. Best is trial 15 with value: 0.8725490196078431.\n",
      "[I 2024-05-10 20:45:26,928] Trial 16 finished with value: 0.8731617647058824 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.47965473281863374}. Best is trial 16 with value: 0.8731617647058824.\n",
      "[I 2024-05-10 20:45:27,690] Trial 17 finished with value: 0.8814180929095354 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.75639027725269}. Best is trial 17 with value: 0.8814180929095354.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:45:34,323] Trial 18 finished with value: 0.8691131498470948 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.7585962203586842}. Best is trial 17 with value: 0.8814180929095354.\n",
      "[I 2024-05-10 20:45:35,211] Trial 19 finished with value: 0.8813455657492353 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8022201351888888}. Best is trial 17 with value: 0.8814180929095354.\n",
      "[I 2024-05-10 20:45:35,965] Trial 20 finished with value: 0.8813455657492353 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.837068343380777}. Best is trial 17 with value: 0.8814180929095354.\n",
      "[I 2024-05-10 20:45:36,723] Trial 21 finished with value: 0.8813455657492353 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8268565829501096}. Best is trial 17 with value: 0.8814180929095354.\n",
      "[I 2024-05-10 20:45:37,479] Trial 22 finished with value: 0.88168755732192 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8484312819652449}. Best is trial 22 with value: 0.88168755732192.\n",
      "[I 2024-05-10 20:45:38,167] Trial 23 finished with value: 0.8769136558481323 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.6399941143748235}. Best is trial 22 with value: 0.88168755732192.\n",
      "[I 2024-05-10 20:45:38,904] Trial 24 finished with value: 0.8820293398533007 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8715178559675737}. Best is trial 24 with value: 0.8820293398533007.\n",
      "[I 2024-05-10 20:45:39,657] Trial 25 finished with value: 0.8823709135349832 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8985394079985123}. Best is trial 25 with value: 0.8823709135349832.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:45:46,417] Trial 26 finished with value: 0.8690330477356182 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.8920405559862974}. Best is trial 25 with value: 0.8823709135349832.\n",
      "[I 2024-05-10 20:45:47,165] Trial 27 finished with value: 0.8825688073394496 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9184984554982554}. Best is trial 27 with value: 0.8825688073394496.\n",
      "[I 2024-05-10 20:45:48,066] Trial 28 finished with value: 0.882640586797066 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9089133127320037}. Best is trial 28 with value: 0.882640586797066.\n",
      "[I 2024-05-10 20:45:48,797] Trial 29 finished with value: 0.8825688073394496 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9205276759894541}. Best is trial 28 with value: 0.882640586797066.\n",
      "[I 2024-05-10 20:45:49,485] Trial 30 finished with value: 0.8751529987760098 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.5945309065235259}. Best is trial 28 with value: 0.882640586797066.\n",
      "[I 2024-05-10 20:45:50,212] Trial 31 finished with value: 0.8825688073394496 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.922159164924134}. Best is trial 28 with value: 0.882640586797066.\n",
      "[I 2024-05-10 20:45:50,942] Trial 32 finished with value: 0.8825688073394496 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9183522095998294}. Best is trial 28 with value: 0.882640586797066.\n",
      "[I 2024-05-10 20:45:51,668] Trial 33 finished with value: 0.8854262144821266 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9896329181893887}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:45:52,487] Trial 34 finished with value: 0.8848151542926977 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9844113992788041}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:45:53,300] Trial 35 finished with value: 0.8850855745721271 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9877469131315944}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:45:54,821] Trial 36 finished with value: 0.8685015290519879 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.9988877900031687}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:45:55,531] Trial 37 finished with value: 0.8700703148884134 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.38963537870717446}. Best is trial 33 with value: 0.8854262144821266.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:46:04,372] Trial 38 finished with value: 0.8690330477356182 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.98948694656716}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:46:05,264] Trial 39 finished with value: 0.8601099572388516 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.77880632163562}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:46:06,355] Trial 40 finished with value: 0.8788249694002448 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.6966953841259846}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:46:07,152] Trial 41 finished with value: 0.8838630806845965 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9522978548788524}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:46:07,868] Trial 42 finished with value: 0.8838630806845965 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9502064346889564}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:46:08,614] Trial 43 finished with value: 0.8848151542926977 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9703491145024439}. Best is trial 33 with value: 0.8854262144821266.\n",
      "[I 2024-05-10 20:46:09,357] Trial 44 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9986103345407616}. Best is trial 44 with value: 0.8856968215158926.\n",
      "[I 2024-05-10 20:46:09,734] Trial 45 finished with value: 0.8100961538461539 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.15285476600442371}. Best is trial 44 with value: 0.8856968215158926.\n",
      "[I 2024-05-10 20:46:10,523] Trial 46 finished with value: 0.8856968215158926 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9987379755120555}. Best is trial 44 with value: 0.8856968215158926.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-05-10 20:46:17,476] Trial 47 finished with value: 0.8690330477356182 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.8529957783580568}. Best is trial 44 with value: 0.8856968215158926.\n",
      "[I 2024-05-10 20:46:18,250] Trial 48 finished with value: 0.8854262144821266 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9957546442878229}. Best is trial 44 with value: 0.8856968215158926.\n",
      "[I 2024-05-10 20:46:19,174] Trial 49 finished with value: 0.8598473282442748 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.7250698050765814}. Best is trial 44 with value: 0.8856968215158926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 2.33 s, total: 1min 31s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_log_reg, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9986103345407616}\n",
      "f1_score на обучающем наборе: 0.89\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = linear_model.LogisticRegression(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Использование Optuna также не улучшило нашу метрику, F1 = 0.78**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Случайный лес\n",
    "Теперь обучим модель случайного леса и подберем для нее гиперпараметры с помощью базовых и продвинутых методом оптимизации.\n",
    "\n",
    "Зафиксируем метрики, которые были получены без дополнительной настройки, т.е со значениями гиперпараметров, установленных по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.00\n",
      "Test: 0.81\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса случайный лес\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Обучаем модель\n",
    "rf.fit(X_train, y_train)\n",
    "#Выводим значения метрики \n",
    "y_train_pred = rf.predict(X_train)\n",
    "print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.43 s, sys: 541 ms, total: 3.97 s\n",
      "Wall time: 1min 44s\n",
      "f1_score на обучающем наборе: 0.94\n",
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.82\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
    "              }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = grid_search_forest.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = grid_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Использование GridSearchCV позволило увеличить нашу метрику F1 с 0.81 до 0.82**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 40 is smaller than n_iter=50. Running 40 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.3 s, sys: 605 ms, total: 4.9 s\n",
      "Wall time: 3min 26s\n",
      "f1_score на обучающем наборе: 0.94\n",
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.82\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 140, 'min_samples_leaf': 5, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 10, dtype=int))\n",
    "              }\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5,\n",
    "    n_iter = 50, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = random_search_forest.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = random_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Использование GridSearchCV также позволило увеличить нашу метрику F1 с 0.81 до 0.82**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperopt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={'n_estimators': hp.quniform('n_estimators', 80, 200, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 40, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:43<00:00,  3.27s/trial, best loss: -0.992651561543172] \n",
      "Наилучшие значения гиперпараметров {'max_depth': 25.0, 'min_samples_leaf': 2.0, 'n_estimators': 174.0}\n",
      "CPU times: user 2min 33s, sys: 3.82 s, total: 2min 36s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=50, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.99\n",
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Использование Hyperopt также позволило увеличить нашу метрику F1 с 0.81 до 0.82**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
    "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-10 21:49:45,538] A new study created in memory with name: RandomForestClassifier\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:49:49,407] Trial 0 finished with value: 0.9779546846295162 and parameters: {'n_estimators': 110, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:49:52,521] Trial 1 finished with value: 0.9600487953644403 and parameters: {'n_estimators': 130, 'max_depth': 23, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:49:57,077] Trial 2 finished with value: 0.9354147535965719 and parameters: {'n_estimators': 210, 'max_depth': 25, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:01,386] Trial 3 finished with value: 0.9358582773365914 and parameters: {'n_estimators': 160, 'max_depth': 27, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:04,119] Trial 4 finished with value: 0.9590714722052536 and parameters: {'n_estimators': 100, 'max_depth': 23, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:07,698] Trial 5 finished with value: 0.9336999694469906 and parameters: {'n_estimators': 170, 'max_depth': 36, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:14,559] Trial 6 finished with value: 0.9776690119302539 and parameters: {'n_estimators': 270, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:17,858] Trial 7 finished with value: 0.9709923664122138 and parameters: {'n_estimators': 100, 'max_depth': 16, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.9779546846295162.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:25,267] Trial 8 finished with value: 0.97796817625459 and parameters: {'n_estimators': 210, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 8 with value: 0.97796817625459.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:29,547] Trial 9 finished with value: 0.9908144519289651 and parameters: {'n_estimators': 140, 'max_depth': 38, 'min_samples_leaf': 2}. Best is trial 9 with value: 0.9908144519289651.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:39,270] Trial 10 finished with value: 0.9911124731841863 and parameters: {'n_estimators': 260, 'max_depth': 39, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9911124731841863.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:47,819] Trial 11 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 300, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9920245398773007.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:50:55,687] Trial 12 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 300, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9920245398773007.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:03,055] Trial 13 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 300, 'max_depth': 33, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9920245398773007.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:10,447] Trial 14 finished with value: 0.9460201280878316 and parameters: {'n_estimators': 300, 'max_depth': 34, 'min_samples_leaf': 5}. Best is trial 11 with value: 0.9920245398773007.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:15,460] Trial 15 finished with value: 0.9273060476481368 and parameters: {'n_estimators': 250, 'max_depth': 40, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.9920245398773007.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:22,012] Trial 16 finished with value: 0.9926470588235294 and parameters: {'n_estimators': 220, 'max_depth': 32, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:29,613] Trial 17 finished with value: 0.9583843329253365 and parameters: {'n_estimators': 220, 'max_depth': 32, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:39,494] Trial 18 finished with value: 0.9895897121861605 and parameters: {'n_estimators': 240, 'max_depth': 18, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:44,219] Trial 19 finished with value: 0.9460858970453853 and parameters: {'n_estimators': 190, 'max_depth': 36, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:51:52,181] Trial 20 finished with value: 0.97796817625459 and parameters: {'n_estimators': 280, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:00,563] Trial 21 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 280, 'max_depth': 37, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:07,444] Trial 22 finished with value: 0.9917304747320062 and parameters: {'n_estimators': 230, 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:14,012] Trial 23 finished with value: 0.9782808198225759 and parameters: {'n_estimators': 300, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:21,384] Trial 24 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 280, 'max_depth': 31, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:28,303] Trial 25 finished with value: 0.9914163090128756 and parameters: {'n_estimators': 250, 'max_depth': 38, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:31,562] Trial 26 finished with value: 0.9754751686082158 and parameters: {'n_estimators': 80, 'max_depth': 34, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:37,053] Trial 27 finished with value: 0.9587029672682778 and parameters: {'n_estimators': 200, 'max_depth': 40, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:43,634] Trial 28 finished with value: 0.9911179173047474 and parameters: {'n_estimators': 270, 'max_depth': 20, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:50,133] Trial 29 finished with value: 0.9788797061524334 and parameters: {'n_estimators': 290, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:52:54,310] Trial 30 finished with value: 0.978267523722069 and parameters: {'n_estimators': 180, 'max_depth': 37, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:01,490] Trial 31 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 300, 'max_depth': 34, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:07,753] Trial 32 finished with value: 0.9911124731841863 and parameters: {'n_estimators': 260, 'max_depth': 32, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:14,636] Trial 33 finished with value: 0.9917203311867526 and parameters: {'n_estimators': 290, 'max_depth': 29, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:18,413] Trial 34 finished with value: 0.9911179173047474 and parameters: {'n_estimators': 150, 'max_depth': 32, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:23,382] Trial 35 finished with value: 0.9596330275229358 and parameters: {'n_estimators': 230, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:30,467] Trial 36 finished with value: 0.9782808198225759 and parameters: {'n_estimators': 300, 'max_depth': 38, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:35,508] Trial 37 finished with value: 0.9263672471738467 and parameters: {'n_estimators': 270, 'max_depth': 33, 'min_samples_leaf': 7}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:38,292] Trial 38 finished with value: 0.9761613691931541 and parameters: {'n_estimators': 120, 'max_depth': 36, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:44,363] Trial 39 finished with value: 0.946886446886447 and parameters: {'n_estimators': 290, 'max_depth': 26, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:50,692] Trial 40 finished with value: 0.9917254060680356 and parameters: {'n_estimators': 260, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:53:57,567] Trial 41 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 280, 'max_depth': 37, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:04,302] Trial 42 finished with value: 0.9920245398773007 and parameters: {'n_estimators': 280, 'max_depth': 39, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:10,783] Trial 43 finished with value: 0.9782808198225759 and parameters: {'n_estimators': 290, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:16,992] Trial 44 finished with value: 0.9914163090128756 and parameters: {'n_estimators': 250, 'max_depth': 37, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:23,481] Trial 45 finished with value: 0.9911070223857713 and parameters: {'n_estimators': 270, 'max_depth': 39, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:30,350] Trial 46 finished with value: 0.9782808198225759 and parameters: {'n_estimators': 300, 'max_depth': 35, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:34,474] Trial 47 finished with value: 0.935454267360049 and parameters: {'n_estimators': 210, 'max_depth': 40, 'min_samples_leaf': 6}. Best is trial 16 with value: 0.9926470588235294.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:38,663] Trial 48 finished with value: 0.9932639314145744 and parameters: {'n_estimators': 170, 'max_depth': 38, 'min_samples_leaf': 2}. Best is trial 48 with value: 0.9932639314145744.\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 80, 300, 10)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 15, 40, 1)\n",
      "/var/folders/jr/y6j710014w98cjhsh00zh_gw0000gn/T/ipykernel_11842/1781554741.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 7, 1)\n",
      "[I 2024-05-10 21:54:42,553] Trial 49 finished with value: 0.9920343137254902 and parameters: {'n_estimators': 160, 'max_depth': 38, 'min_samples_leaf': 2}. Best is trial 48 with value: 0.9932639314145744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 15s, sys: 6.32 s, total: 4min 22s\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 170, 'max_depth': 38, 'min_samples_leaf': 2}\n",
      "f1_score на обучающем наборе: 0.99\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**И наконец использование Optuna также позволило увеличить нашу метрику F1 с 0.81 до 0.82**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
